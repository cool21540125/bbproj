{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as r\n",
    "import lxml\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "import sqlite3\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "import argparse\n",
    "import math\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- 共用模組 ---\n",
    "import public_crawler\n",
    "# --- 信義房屋專用模組 ---\n",
    "import crawler_sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看DB的結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rental',)]\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect('sy.db') as conn:\n",
    "    c = conn.cursor()\n",
    "    pprint.pprint(list(c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")))\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with sqlite3.connect('sy.db') as conn:\n",
    "#     c = conn.cursor()\n",
    "#     qry = \"Create Table rental (url text unique not null,  title text, main text, detail text,  nosql text,  rdb text,  getTime text )\"\n",
    "#     c.execute(qry)\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with sqlite3.connect('sy.db') as conn:\n",
    "#     c = conn.cursor()\n",
    "#     c.execute('delete from rental')\n",
    "#     c.execute('select count(*) from rental')\n",
    "#     print(c.fetchall())\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with sqlite3.connect('sy.db') as conn:\n",
    "#     c = conn.cursor()\n",
    "#     qry = \"select count(*) from rental\"\n",
    "#     c.execute(qry)\n",
    "#     print(c.fetchall())\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.外頁網址, 依照不同房仲網, 解析出各自的urls\n",
    "def extractAllUrls(dbName, soup):\n",
    "    try:\n",
    "        allUrls = []\n",
    "        if dbName == 'sy.db':\n",
    "            for url_raw in soup.select('a.name'):\n",
    "                url = url_raw['href']\n",
    "                allUrls.append(url)\n",
    "            return allUrls\n",
    "        elif dbName == 'yc.db':\n",
    "            pass\n",
    "        elif dbName == 'jc.db':\n",
    "            pass\n",
    "        elif dbName == 'hf.db':\n",
    "            pass\n",
    "        else:\n",
    "            print('沒有這個db...' + dbName + 'public_crawler.extractAllUrls')\n",
    " \n",
    "    except Exception as err:\n",
    "        print('解析allUrls Error' + dbName)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.查詢內頁全部 _ 逐項拆解\n",
    "def queryByURL(url):\n",
    "    try:\n",
    "        res = r.get(url)\n",
    "        soup = bs(res.text, 'lxml')\n",
    "        \n",
    "        # 內頁標題\n",
    "        title = extract_title_sy(soup, url)\n",
    "        # 內頁表格主要資訊\n",
    "        main = extract_main_sy(soup, url)\n",
    "        # 內頁表格明細資訊\n",
    "        detail = extract_detail_sy(soup, url)\n",
    "        \n",
    "        return title, main, detail\n",
    "        \n",
    "    except Exception as err:\n",
    "        print(title + \" ; 內頁soup.select時Error ; \" + url)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 抓外頁網址\n",
    "# 給我\n",
    "# 1. 要儲存的dbName\n",
    "# 2. outerPageETL()回傳的urls\n",
    "# 這支程式會做1件事情: 叫另外2支程式做事情\n",
    "# 1. 爬取每個網址內的頁面資訊 -> soupText (str datatype)\n",
    "# 2. 把soupText依照dbName存到所屬的sqlite     \"\"public_crawler.py\"\"\n",
    "# !!!!! 睡 1 秒 !!!!!\n",
    "def innerPageETL(dbName, urls):\n",
    "    i = 0\n",
    "    for url in urls:\n",
    "        try:\n",
    "            i = i + innerPageETL_one(dbName, url)\n",
    "        except Exception as err:\n",
    "            print('innerPageETL --- Something Error')\n",
    "        time.sleep(1)\n",
    "    return i\n",
    "\n",
    "# 同innerPageETL, 但僅執行一筆\n",
    "def innerPageETL_one(dbName, url):\n",
    "    try:\n",
    "        # 信義房屋會檢查headers\n",
    "        title, main, detail = queryByURL(url)\n",
    "\n",
    "        if (title == '' or isinstance(main, str) or isinstance(detail, str)):\n",
    "            return 0\n",
    "        \n",
    "        else:\n",
    "            return insertToDB(dbName, url, title, str(main), str(detail))\n",
    "#             return public_crawler.insertToDB(dbName, url, title, str(main), str(detail))\n",
    "        \n",
    "    except Exception as err:\n",
    "        print(str(err) + ' ; url = ' + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 儲存內頁到所屬資料庫\n",
    "# 告訴我你要放進去的\n",
    "# Sqlite Name,  url,  soup\n",
    "# 會幫你把 url , soup 依照現在時間, 存入你指定的database的rental table內\n",
    "# 回傳1 表示成功匯入\n",
    "# 回傳0 表示之前已經存過此網址\n",
    "# 回傳0 + print(xxx ; Error url : xxx)  表示資料庫連接有問題\n",
    "#  -> 可能是你把不適合的資料塞進來了 or\n",
    "#  -> create table本身就有點問題\n",
    "def insertToDB(dbName, url, title, main, detail):\n",
    "    try:\n",
    "        with sqlite3.connect(dbName) as conn:\n",
    "            c = conn.cursor()\n",
    "            # 執行查詢字串\n",
    "            getTime = str(datetime.now())\n",
    "            queryString = \"SELECT url FROM rental WHERE url = '\" + url + \"'\"\n",
    "            c.execute(queryString)\n",
    "            if (len(c.fetchall()) == 0):\n",
    "                insertStr = 'INSERT INTO rental(url, title, main, detail, getTime) VALUES (?, ?, ?, ?, ?)'\n",
    "                values = (url, title, main, detail, getTime)\n",
    "                \n",
    "                c.execute(insertStr, values)\n",
    "                return 1\n",
    "                \n",
    "            else:\n",
    "                # 重複出現的網址(不儲存)\n",
    "                print(dbName + ' : ' + url + ' ---------------- repeat')\n",
    "                return 0\n",
    "                \n",
    "    except Exception as err:\n",
    "        print(str(err) + ' ; Error url : ' + url)\n",
    "        return 0\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 外網解析時, 抓到網址清單, 逐筆檢查此url是否已有\n",
    "def saveThisUrl(dbName, url):\n",
    "    try:\n",
    "        with sqlite3.connect(dbName) as conn:\n",
    "            c = conn.cursor()\n",
    "            c.execute(\"SELECT url FROM rental WHERE url = '\" + url + \"'\")\n",
    "            if (len(c.fetchall()) == 0):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    except Exception as err:\n",
    "        print('Repeat check error with(不明錯誤) : ' + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 特定頁面所有網址, 到資料庫看有沒有儲存過, 沒有的話再把他堆疊, 最後回傳\n",
    "def filterUrls(dbName, all_urls):\n",
    "    urls = []\n",
    "    for url in all_urls:\n",
    "        if saveThisUrl(dbName, url):\n",
    "            urls.append(url)\n",
    "            \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 外頁總頁數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTotalPage_sy(url):\n",
    "    res = r.get(url)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    nums = soup.select('h1')[0].text\n",
    "\n",
    "    regex = re.compile('\\d*[,]?\\d+')\n",
    "    nums = int(regex.search(nums).group().replace(',', ''))\n",
    "    return math.ceil(int(nums) / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 衣外網抓總頁數\n",
    "src = \"http://rent.sinyi.com.tw/AJAX/ajax_searchItem.php?search=1&b=26\"\n",
    "getTotalPage_sy(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 外頁爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=CA17405'\n",
    "res = r.get(url)\n",
    "soup = bs(res.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=237747',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=237383',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236742',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236738',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236697',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236696',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236691',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236687',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236479',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236476',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236457',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236452',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236296',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236295',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236292',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236284',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236276',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236161',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=236136',\n",
       " 'http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=234935']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取得網址清單\n",
    "tmp = soup.select('a.name')\n",
    "urls = []\n",
    "for url in tmp:\n",
    "    urls.append(url['href'])\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 內頁明細"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 內頁拆解\n",
    "def extract_title(soup, url):\n",
    "    try:\n",
    "        title = soup.select('h1')[0].text\n",
    "        \n",
    "    except Exception as err:\n",
    "        print('title error : ' + url)\n",
    "        title = ''\n",
    "    finally:\n",
    "        return title\n",
    "#\n",
    "\n",
    "\n",
    "# 主要段落\n",
    "def extract_main(soup, url):\n",
    "    main = {}\n",
    "    try:\n",
    "        soup_main = soup.select('div#summary')[0]    \n",
    "        main['addr'] = soup_main.select('div.addr')[0].text #大概在哪邊\n",
    "        main['rent'] = soup_main.select('span.rent')[0].text    # 租金\n",
    "        if soup_main.select('span.deposite'):\n",
    "            main['deposite'] = soup_main.select('span.deposite')[0].text    # 押金\n",
    "        main['type'] = soup_main.select('div.type')[0].text.replace('房屋類型', '')    # 房屋類型 \n",
    "        main['size'] = soup_main.select('td')[0].text    # 坪數\n",
    "        main['floor'] = soup_main.select('td')[1].text    # 樓層\n",
    "        main['pattern'] = soup_main.select('td')[2].text    # 格局\n",
    "\n",
    "        #生活周邊\n",
    "        env = '' \n",
    "        env_list = soup.find_all('a',{'href':'javascript:;'}) \n",
    "        for i in range(len(env_list) -1 ): #最後個是加入追蹤不加入迴圈,故減去一\n",
    "            env = env + env_list[i]['title'] + \"、\" #每加一次後面加上個 (、)  方便辨識\n",
    "        main['envir'] = env\n",
    "        \n",
    "        #經緯度\n",
    "        if soup.find('img',id='static_map2') != None:\n",
    "            lat_and_lng = soup.find('img',id='static_map2')['src'].replace('.png','').split('_')\n",
    "            main['latlng'] = lat_and_lng[-2] + ',' + lat_and_lng[-1]\n",
    "        else:\n",
    "            main['latlng'] = ''\n",
    "        \n",
    "    except Exception as err:\n",
    "        print('main error : ' + url)\n",
    "        main = ''\n",
    "        \n",
    "    finally:\n",
    "        return main\n",
    "#\n",
    "\n",
    "\n",
    "# 詳細資料\n",
    "def extract_detail(soup, url):\n",
    "    detail = {}\n",
    "    try:\n",
    "        detail_keys = soup.find('section',id='mainInfo').find_all('th')\n",
    "        detail_values = soup.find('section',id='mainInfo').find_all('td')\n",
    "        detail = {key.text.replace('\\u3000','') : values.text.replace(' ','').replace('\\t','').replace('\\n','') \n",
    "                       for key , values in zip(detail_keys, detail_values)} \n",
    "\n",
    "        #食、住、行、樂 如果是車位/土地/場地,  則無 周邊生活資訊的tag\n",
    "        house_type = soup.find('div','type').text.replace('房屋類型','')\n",
    "        if house_type != '土地/場地' and house_type != '車位':\n",
    "            live_demand = soup.find('section',id='surround').find_all('p')\n",
    "            for i in live_demand:\n",
    "                detail[i.find('span').text] = i.text[1:]\n",
    "\n",
    "        if soup.select(\"#agreement\"):\n",
    "            for ttr in soup.select('#agreement')[0].select('tr'):\n",
    "                detail[ttr.select('th')[0].text] = ttr.select('td')[0].text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "    except Exception as err:\n",
    "        print('detail error : ' + url)\n",
    "        detail = ''\n",
    "        \n",
    "    finally:\n",
    "        return detail\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25.0536,121.6009'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_and_lng = soup.find('img',id='static_map2')['src'].replace('.png','').split('_')\n",
    "\n",
    "lat_and_lng[-2] + ',' + lat_and_lng[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if soup.select('span.deposite'):    # 押金\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 內頁解析 - 測試程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://rent.sinyi.com.tw/itemDetail.php?s=1&itemid=CA15248\"\n",
    "res = r.get(url)\n",
    "soup = bs(res.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('input#GPSLatiude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('input#GPSLongitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f526374de5d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input#GPSLongitude'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "float(soup.select('input#GPSLongitude')[0]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'addr': '天母揚明\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000(CA15248)',\n",
       " 'deposite': '押金：110000元',\n",
       " 'envir': '',\n",
       " 'floor': '2樓/ 共7樓',\n",
       " 'latlng': '-0.0022,118.7618',\n",
       " 'pattern': '3房2廳2衛',\n",
       " 'rent': '55,000元',\n",
       " 'size': '43.53坪',\n",
       " 'type': '整層住宅'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = extract_title(soup, url)\n",
    "main = extract_main(soup, url)\n",
    "detail = extract_detail(soup, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-00e84adac83a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'th'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mttr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'td'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mm' is not defined"
     ]
    }
   ],
   "source": [
    "detail_keys = soup.find('section',id='mainInfo').find_all('th')\n",
    "detail_values = soup.find('section',id='mainInfo').find_all('td')\n",
    "detail = {key.text.replace('\\u3000','') : values.text.replace(' ','').replace('\\t','').replace('\\n','') \n",
    "               for key , values in zip(detail_keys, detail_values)} \n",
    "\n",
    "#食、住、行、樂 如果是車位/土地/場地,  則無 周邊生活資訊的tag\n",
    "house_type = soup.find('div','type').text.replace('房屋類型','')\n",
    "\n",
    "if house_type != '土地/場地' and house_type != '車位':\n",
    "    live_demand = soup.find('section',id='surround').find_all('p')\n",
    "    for i in live_demand:\n",
    "        detail[i.find('span').text] = i.text[1:]\n",
    "\n",
    "if soup.select(\"#agreement\"):\n",
    "\n",
    "    for ttr in soup.select('#agreement')[0].select('tr'):\n",
    "        print(ttr)\n",
    "        mm[ttr.select('th')[0].text] = ttr.select('td')[0].text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'details': {'傢俱設備': '否',\n",
       "  '出租坪數': '166.64坪',\n",
       "  '地址': '台北市內湖區新湖一路',\n",
       "  '屋齡': '332000元',\n",
       "  '建物坪數': '196.7坪',\n",
       "  '押金': '17,000元',\n",
       "  '暗房': '是',\n",
       "  '格局': '4房2廳',\n",
       "  '樓層': '4樓/總樓層7',\n",
       "  '租金': '166,000元/月',\n",
       "  '管理警衛': '',\n",
       "  '管理費': '本物件係為分隔出租，出租面積約為166.64坪。然實際大小應以現場丈量、目測為準。',\n",
       "  '車位': '5年',\n",
       "  '邊間': '無',\n",
       "  '類型': '辦公/廠房',\n",
       "  '食': '(市場、商圈) 近傳統市場'},\n",
       " 'getTime': '2017-06-23',\n",
       " 'main': {'建物坪數': '196.7坪',\n",
       "  '房屋類型': '辦公/廠房',\n",
       "  '押金': '332000元',\n",
       "  '格局': '4房2廳',\n",
       "  '樓層': '4樓/ 共7樓',\n",
       "  '生活周邊': '',\n",
       "  '租金': '\\n166,000元/月租\\n                                                        押金：332000元\\n',\n",
       "  '經緯度': '25.0586,121.5759'},\n",
       " 'title': '瑞士百坪帶裝潢'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch_details(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def catch_details(url,json_signal=False):\n",
    "    \n",
    "    from bs4 import BeautifulSoup\n",
    "    from datetime import date\n",
    "    import requests\n",
    "    import json\n",
    "    import lxml\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    info = BeautifulSoup(res.text,'lxml')\n",
    "    all_dict = {}\n",
    "    \n",
    "    #-----------------------------------去除區(土地、車位)-----------------------------------------#\n",
    "    \n",
    "    house_type = info.find('div','type').text.replace('房屋類型','')\n",
    "    if house_type == '土地/場地' or house_type == '車位':\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "\n",
    "        #-----------------------------------標題、getTime---------------------------------------------#\n",
    "\n",
    "        #標題\n",
    "        all_dict['title'] = info.find('h1').text\n",
    "        #更新時間\n",
    "        all_dict['getTime'] = str(date.today())\n",
    "\n",
    "\n",
    "\n",
    "        #-----------------------------------主要資訊區---------------------------------------------#\n",
    "\n",
    "        main_info = {}\n",
    "\n",
    "        #租金\n",
    "        main_info['租金'] = info.find('div','price').text\n",
    "        #押金\n",
    "        if info.find('span','deposite') != None :\n",
    "            main_info['押金'] = info.find('span','deposite').text.replace('押金：','')\n",
    "        else:\n",
    "            main_info['押金'] = '' #如果要簡化資料庫效率，可在這轉換為數字0，\n",
    "\n",
    "        #房屋類型\n",
    "        if info.find('div','type') != None :\n",
    "            main_info['房屋類型'] = info.find('div','type').text.replace('房屋類型','')\n",
    "        else:\n",
    "            main_info['房屋類型'] =''\n",
    "\n",
    "        #建物坪數、樓層、格局\n",
    "        main_keys = info.find('table').find_all('th')\n",
    "        main_values = info.find('table').find_all('td')\n",
    "        main_items = {key.text : values.text for key , values in zip(main_keys,main_values)} #迴圈進入dict\n",
    "        main_info.update(main_items) #dict合併\n",
    "\n",
    "        #生活周邊\n",
    "        env = '' \n",
    "        env_list = info.find_all('a',{'href':'javascript:;'}) \n",
    "        for i in range(len(env_list) -1 ): #最後個是加入追蹤不加入迴圈,故減去一\n",
    "            env = env + env_list[i]['title'] + \"、\" #每加一次後面加上個 (、)  方便辨識\n",
    "        main_info['生活周邊'] = env\n",
    "\n",
    "        #經緯度\n",
    "        if info.find('img',id='static_map2') != None:\n",
    "            lat_and_lng = info.find('img',id='static_map2')['src'].replace('.png','').split('_')\n",
    "            main_info['經緯度'] = lat_and_lng[-2] + ',' + lat_and_lng[-1]\n",
    "        else:\n",
    "            main_info['經緯度'] = ''\n",
    "\n",
    "        all_dict['main'] = main_info\n",
    "\n",
    "        #-----------------------------------詳細資料區-----------------------------------------------#\n",
    "        #地址、租金、類型、格局、樓層、遷入日期、建物坪數、管理費、押金、朝向、屋齡、車位、邊間、暗房、隔間材料、傢俱設備、\n",
    "        #其他室友、房東同住、房東身份、仲介服務費、最短租期、辦理租約公證、房客提供身份證件備存、管理警衛(有些有有些無)\n",
    "        details_info = {}\n",
    "        details_keys = info.find('section',id='mainInfo').find_all('th')\n",
    "        details_values = info.find('section',id='mainInfo').find_all('td')\n",
    "        details_info = {key.text.replace('\\u3000','') : values.text.replace(' ','').replace('\\t','').replace('\\n','') \n",
    "                       for key , values in zip(details_keys,details_values)} \n",
    "\n",
    "        #食、住、行、樂\n",
    "        live_demand = info.find('section',id='surround').find_all('p')\n",
    "        for i in live_demand:\n",
    "            details_info[i.find('span').text] = i.text[1:]\n",
    "\n",
    "        all_dict['details'] = details_info\n",
    "\n",
    "\n",
    "        if json_signal == False:\n",
    "            return all_dict\n",
    "        else:\n",
    "            return json.dumps(all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cc53fb8d65d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#mainInfo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#     print(r)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#     print('---------------')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "for r in soup.select('#mainInfo')[0]:\n",
    "    pass\n",
    "#     print(r)\n",
    "#     print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with sqlite3.connect('jc.db') as conn:\n",
    "    c = conn.cursor()\n",
    "    c.execute('drop table rental')\n",
    "c.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
